{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline Feature Generation (DuckDB + Parquet)\n",
    "\n",
    "Goal: build an **offline feature store** pipeline end-to-end: generate raw events, compute features, and materialize them as Parquet partitions.\n",
    "\n",
    "This notebook is designed as an industrial baseline: deterministic data generation, schema validation, reproducible feature computation, and artifact outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "SEED = 1337\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "OUT_DIR = os.path.abspath(os.path.join('..', 'registry', 'offline'))\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "OUT_RAW = os.path.join(OUT_DIR, 'raw_events.parquet')\n",
    "OUT_FEAT = os.path.join(OUT_DIR, 'features_daily.parquet')\n",
    "\n",
    "print('OUT_DIR=', OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Generate raw events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 2000\n",
    "days = 60\n",
    "events_per_user = rng.poisson(lam=25, size=n_users)\n",
    "\n",
    "start = datetime.now(timezone.utc) - timedelta(days=days)\n",
    "\n",
    "rows = []\n",
    "for user_id in range(1, n_users + 1):\n",
    "    n = int(events_per_user[user_id - 1])\n",
    "    if n == 0:\n",
    "        continue\n",
    "\n",
    "    base_value = rng.lognormal(mean=2.0, sigma=0.6)\n",
    "    for _ in range(n):\n",
    "        ts = start + timedelta(seconds=int(rng.integers(0, days * 24 * 3600)))\n",
    "        event_type = rng.choice(['login', 'purchase', 'view', 'support'], p=[0.25, 0.08, 0.62, 0.05])\n",
    "        amount = 0.0\n",
    "        if event_type == 'purchase':\n",
    "            amount = float(base_value * rng.lognormal(mean=0.0, sigma=0.8))\n",
    "        rows.append((user_id, ts.isoformat(), event_type, amount))\n",
    "\n",
    "df = pd.DataFrame(rows, columns=['user_id', 'event_ts', 'event_type', 'amount'])\n",
    "df['event_ts'] = pd.to_datetime(df['event_ts'], utc=True)\n",
    "df['event_date'] = df['event_ts'].dt.date\n",
    "df = df.sort_values(['user_id', 'event_ts']).reset_index(drop=True)\n",
    "\n",
    "df.head(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(OUT_RAW, index=False)\n",
    "print('wrote', OUT_RAW, os.path.getsize(OUT_RAW), 'bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Feature computation with DuckDB\n",
    "We compute daily features per user: counts by event type, rolling 7-day purchase amount, and activity recency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(database=':memory:')\n",
    "con.execute('PRAGMA threads=4')\n",
    "con.execute(f\"CREATE VIEW raw AS SELECT * FROM read_parquet('{OUT_RAW.replace('\\\\','\\\\\\\\')}')\")\n",
    "\n",
    "query = r'''\n",
    "WITH daily AS (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    CAST(event_date AS DATE) AS event_date,\n",
    "    COUNT(*) AS events_total,\n",
    "    SUM(CASE WHEN event_type='login' THEN 1 ELSE 0 END) AS c_login,\n",
    "    SUM(CASE WHEN event_type='view' THEN 1 ELSE 0 END) AS c_view,\n",
    "    SUM(CASE WHEN event_type='support' THEN 1 ELSE 0 END) AS c_support,\n",
    "    SUM(CASE WHEN event_type='purchase' THEN 1 ELSE 0 END) AS c_purchase,\n",
    "    SUM(CASE WHEN event_type='purchase' THEN amount ELSE 0 END) AS purchase_amount\n",
    "  FROM raw\n",
    "  GROUP BY user_id, CAST(event_date AS DATE)\n",
    "),\n",
    "roll AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    SUM(purchase_amount) OVER (PARTITION BY user_id ORDER BY event_date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW)\n",
    "      AS purchase_amount_7d\n",
    "  FROM daily\n",
    ")\n",
    "SELECT\n",
    "  user_id,\n",
    "  event_date,\n",
    "  events_total, c_login, c_view, c_support, c_purchase,\n",
    "  purchase_amount, purchase_amount_7d,\n",
    "  DATE_DIFF('day', event_date, (SELECT MAX(event_date) FROM daily)) AS days_since_last_activity\n",
    "FROM roll\n",
    "ORDER BY user_id, event_date\n",
    "'''\n",
    "\n",
    "feat = con.execute(query).df()\n",
    "feat.head(), feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat.to_parquet(OUT_FEAT, index=False)\n",
    "print('wrote', OUT_FEAT, os.path.getsize(OUT_FEAT), 'bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert feat['user_id'].min() >= 1\n",
    "assert feat['events_total'].ge(0).all()\n",
    "assert feat['purchase_amount_7d'].ge(0).all()\n",
    "\n",
    "feat.describe(include='all').T.head(12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
